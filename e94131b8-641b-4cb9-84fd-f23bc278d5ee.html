<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1,shrink-to-fit=no name=viewport><meta name=description><meta name=author><title>dialog.sdwh</title><link href=assets/favicon.ico rel=icon type=image/x-icon><link href=css/styles.css rel=stylesheet><link href=css/site.css?v=2 rel=stylesheet><style>@import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400&display=swap');</style><body><nav class="navbar navbar-expand-lg navbar-dark bg-dark"><div class=container><a class=navbar-brand href=https://dialog.sdwh.dev/>dialog.sdwh</a><button aria-label="Toggle navigation"aria-controls=navbarSupportedContent aria-expanded=false class=navbar-toggler data-bs-target=#navbarSupportedContent data-bs-toggle=collapse type=button><span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse"id=navbarSupportedContent><ul class="navbar-nav ms-auto mb-2 mb-lg-0"><li class=nav-item><a class="nav-link active"aria-current=page href=#>Home</a><li class=nav-item><a class=nav-link href=https://sdwh.dev/about/ target=_blank>About</a></ul></div></div></nav><div class=container><div id=post-content></div><div class=row><div class="conversation col-12 col-lg-6"><p class=message>Hi B, have you thought about how we can improve our testing coverage?<p class="message sent">Yeah, I've been thinking about it recently. One of the things we could do is implement functional testing for every single feature.<p class=message>That sounds great. But what if we miss something?<p class="message sent">We can always perform exploratory testing to identify any missed defects.<p class=message>Right, that makes sense. Another way to improve our testing would be to implement automation testing.<p class="message sent">Yes, automation testing can really speed up our testing and increase our testing coverage.<p class=message>But we also need to be careful with automation testing too. It's easy to fall into the trap of thinking that automated tests can replace manual tests entirely.<p class="message sent">Exactly! That's why we should only use automation testing for repeatable tasks that don't require human intervention.<p class=message>We could also consider using static code analysis tools to identify potential defects before we even start testing.<p class="message sent">That's a good point. But remember not all defects can be found with static code analysis. We still need to perform testing regardless.<p class=message>Of course! Speaking of which, have you considered using boundary testing to test the extremes of input values?<p class="message sent">I have. But we also need to perform equivalence partitioning to ensure we test all possible input values.<p class=message>That's a great idea. What about creating a comprehensive testing plan to ensure we test every feature and function?<p class="message sent">Sounds good. We could also create test scenarios and test cases for each feature to ensure complete testing coverage.<p class=message>We should also measure our testing coverage to ensure we hit our target.<p class="message sent">Agreed. But we also need to be realistic with our goals and not focus strictly on achieving 100% testing coverage.<p class=message>Definitely. It's important to balance testing coverage with time and budget constraints.<p class="message sent">Well, we definitely have our work cut out for us. But with a solid testing strategy in place, I'm confident we can improve our testing coverage.<p class=message>Agreed! Thanks B for the discussion. Let's make full testing coverage a reality!</div><div class=col-12><div class="col-lg-6 text-end mx-auto"><a class="btn btn-outline-primary btn-lg mb-3"href=e93cec44-c8af-42eb-8c6e-bc5f1c4436f5.html>Next</a></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js></script><script src=js/scripts.js></script>